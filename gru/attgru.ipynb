{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T15:59:09.058672Z",
     "iopub.status.busy": "2024-12-13T15:59:09.057775Z",
     "iopub.status.idle": "2024-12-13T15:59:13.041386Z",
     "shell.execute_reply": "2024-12-13T15:59:13.040427Z",
     "shell.execute_reply.started": "2024-12-13T15:59:09.058623Z"
    },
    "id": "mbHk-0I5fDwM",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T15:59:13.043687Z",
     "iopub.status.busy": "2024-12-13T15:59:13.043219Z",
     "iopub.status.idle": "2024-12-13T15:59:14.301978Z",
     "shell.execute_reply": "2024-12-13T15:59:14.301286Z",
     "shell.execute_reply.started": "2024-12-13T15:59:13.043644Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n"
     ]
    }
   ],
   "source": [
    "trainloader =  joblib.load('/kaggle/input/data-loader/train_data_loader.pkl')\n",
    "valloader = joblib.load('/kaggle/input/data-loader/val_data_loader.pkl')\n",
    "testloader = joblib.load('/kaggle/input/data-loader/test_data_loader.pkl')\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "train_dataloader = torch.utils.data.DataLoader(trainloader.dataset,batch_size= BATCH_SIZE, shuffle= True)\n",
    "test_dataloader = torch.utils.data.DataLoader(testloader.dataset,batch_size= BATCH_SIZE)\n",
    "val_dataloader = torch.utils.data.DataLoader(valloader.dataset,batch_size= BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T16:33:00.464036Z",
     "iopub.status.busy": "2024-12-13T16:33:00.463680Z",
     "iopub.status.idle": "2024-12-13T16:33:00.470012Z",
     "shell.execute_reply": "2024-12-13T16:33:00.469157Z",
     "shell.execute_reply.started": "2024-12-13T16:33:00.464004Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.attention = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, lstm_output):\n",
    "        \"\"\"\n",
    "        lstm_output: Tensor of shape (batch_size, seq_len, hidden_dim)\n",
    "        \"\"\"\n",
    "        # Compute attention scores\n",
    "        attn_scores = self.attention(lstm_output).squeeze(-1)  # (batch_size, seq_len)\n",
    "        attn_weights = F.softmax(attn_scores, dim=1)  # Normalize scores to probabilities\n",
    "        \n",
    "        # Compute context vector as weighted sum of LSTM outputs\n",
    "        context = torch.bmm(attn_weights.unsqueeze(1), lstm_output).squeeze(1)  # (batch_size, hidden_dim)\n",
    "        \n",
    "        return context, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T16:33:02.932604Z",
     "iopub.status.busy": "2024-12-13T16:33:02.932227Z",
     "iopub.status.idle": "2024-12-13T16:33:02.939813Z",
     "shell.execute_reply": "2024-12-13T16:33:02.938879Z",
     "shell.execute_reply.started": "2024-12-13T16:33:02.932574Z"
    },
    "id": "hy5vE5fPO5-m",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def F1_tensor(y_true, y_pred):\n",
    "    y_true = y_true.to('cpu').numpy()\n",
    "    y_pred = y_pred.to('cpu').numpy()\n",
    "    return f1_score(y_true, y_pred)\n",
    "\n",
    "def Confusion_matrix_tensor(y_true, y_pred):\n",
    "    y_true = y_true.to('cpu').numpy()\n",
    "    y_pred = y_pred.to('cpu').numpy()\n",
    "    return f1_score(y_true, y_pred)\n",
    "\n",
    "def convert_from_tensor(y): #convert from tensor to some kind of array that we can use numpy\n",
    "    return y.cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "def take_all_elem(container, target):\n",
    "    for x in target:\n",
    "        if (x != 0 and x != 1):\n",
    "            container.append(1)\n",
    "        else:\n",
    "            container.append(x)\n",
    "\n",
    "def save_model(model):\n",
    "    MODEL_PATH = Path('/content')\n",
    "    MODEL_PATH.mkdir(parents = True, exist_ok = True)\n",
    "    MODEL_NAME = 'best_GRUmodel.pth'\n",
    "    MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "    print(f'Update new best model to : {MODEL_SAVE_PATH}')\n",
    "    torch.save(obj = model.state_dict(),f = MODEL_SAVE_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T16:34:11.519691Z",
     "iopub.status.busy": "2024-12-13T16:34:11.519031Z",
     "iopub.status.idle": "2024-12-13T16:34:11.526726Z",
     "shell.execute_reply": "2024-12-13T16:34:11.525703Z",
     "shell.execute_reply.started": "2024-12-13T16:34:11.519656Z"
    },
    "id": "2JlNwITjPH9W",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_step(model : nn.Module,\n",
    "               data_loader : torch.utils.data.DataLoader,\n",
    "               loss_function : nn.Module,\n",
    "               optimizer,\n",
    "               device = 'cuda'):\n",
    "    model.train()\n",
    "    loss = 0\n",
    "\n",
    "    all_y_true = []\n",
    "    all_y_pred = []\n",
    "\n",
    "    for (X_train,y_train,mask) in data_loader:\n",
    "        X_train = X_train.to(device)\n",
    "        y_train = y_train.unsqueeze(1).to(device)\n",
    "\n",
    "        y_pred = model(X_train)\n",
    "        y_pred01 = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "        batch_loss = loss_function(y_pred.float(),y_train.float())\n",
    "        loss += batch_loss\n",
    "\n",
    "        take_all_elem(all_y_true,convert_from_tensor(y_train))\n",
    "        take_all_elem(all_y_pred,convert_from_tensor(y_pred01))\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    loss /= len(data_loader)\n",
    "\n",
    "    all_y_true = np.array(all_y_true)\n",
    "    all_y_pred = np.array(all_y_pred)\n",
    "\n",
    "    #print(all_y_true)\n",
    "    #print(np.unique(all_y_true))\n",
    "\n",
    "    print('------------------Train Result----------------------------')\n",
    "    print(f'Training loss : {loss} | F1_score : {f1_score(all_y_true,all_y_pred)}')\n",
    "\n",
    "    print(classification_report(all_y_true, all_y_pred, digits=4))\n",
    "\n",
    "best_f1_score = -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T16:34:19.732427Z",
     "iopub.status.busy": "2024-12-13T16:34:19.731801Z",
     "iopub.status.idle": "2024-12-13T16:34:19.739556Z",
     "shell.execute_reply": "2024-12-13T16:34:19.738654Z",
     "shell.execute_reply.started": "2024-12-13T16:34:19.732390Z"
    },
    "id": "iu8piAnkPNa2",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def test_step(model : nn.Module,\n",
    "              data_loader : torch.utils.data.DataLoader,\n",
    "              loss_function : nn.Module,\n",
    "              optimizer,\n",
    "              device = 'cuda',):\n",
    "\n",
    "    model.eval()\n",
    "    loss,acc = 0,0\n",
    "\n",
    "    all_y_true = []\n",
    "    all_y_pred = []\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        loss = 0\n",
    "\n",
    "        for (X_test,y_test,mask) in data_loader:\n",
    "            X_test = X_test.to(device)\n",
    "            y_test = y_test.to(device)\n",
    "\n",
    "            test_logits = model(X_test).squeeze()\n",
    "            test_01 = torch.round(torch.sigmoid(test_logits))\n",
    "\n",
    "            batch_loss = loss_function(test_logits.float(),y_test.float())\n",
    "\n",
    "            loss += batch_loss\n",
    "\n",
    "            take_all_elem(all_y_true,convert_from_tensor(y_test))\n",
    "            take_all_elem(all_y_pred,convert_from_tensor(test_01))\n",
    "\n",
    "\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "\n",
    "    current_f1_score = f1_score(all_y_true,all_y_pred)\n",
    "    print('------------------Test Result----------------------------')\n",
    "    print(f'Testing loss : {loss} | F1_score : {current_f1_score}')\n",
    "    print('---------------------------------------------------------')\n",
    "\n",
    "    print(classification_report(all_y_true, all_y_pred, digits=4))\n",
    "\n",
    "    global best_f1_score\n",
    "    if (current_f1_score > best_f1_score):\n",
    "        best_f1_score = current_f1_score\n",
    "        save_model(model)\n",
    "\n",
    "matrix_size = (128,768)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T16:34:26.247812Z",
     "iopub.status.busy": "2024-12-13T16:34:26.247456Z",
     "iopub.status.idle": "2024-12-13T16:34:26.253603Z",
     "shell.execute_reply": "2024-12-13T16:34:26.252717Z",
     "shell.execute_reply.started": "2024-12-13T16:34:26.247777Z"
    },
    "id": "fzdMDVtAPQqp",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class GRUmodel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(64001, 768)\n",
    "        self.rnn = nn.GRU(input_size = matrix_size[1],hidden_size = 384,\n",
    "            num_layers = 3, batch_first = True, bidirectional = False)\n",
    "        self.attention = Attention(384)\n",
    "        self.fc = nn.Linear(384,out_features = 1)\n",
    "\n",
    "    #it output [0,1,2,....,seq_length - 1]\n",
    "    #just take the last array element in case of classification or anything like that\n",
    "    def forward(self, X, state=None):\n",
    "        X = self.embedding(X)\n",
    "        gru_outputs, _ = self.rnn(X, state)\n",
    "        context, attn_weights = self.attention(gru_outputs)\n",
    "        return self.fc(context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T16:34:27.967101Z",
     "iopub.status.busy": "2024-12-13T16:34:27.966428Z",
     "iopub.status.idle": "2024-12-13T16:34:28.549772Z",
     "shell.execute_reply": "2024-12-13T16:34:28.549038Z",
     "shell.execute_reply.started": "2024-12-13T16:34:27.967062Z"
    },
    "id": "Ps5B2GbBPS3G",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = GRUmodel().to(device)\n",
    "BCE_loss = nn.BCEWithLogitsLoss()\n",
    "Adam_optimizer = torch.optim.AdamW(params = model.parameters(),lr = 0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-13T16:34:29.911877Z",
     "iopub.status.busy": "2024-12-13T16:34:29.911539Z",
     "iopub.status.idle": "2024-12-13T16:39:03.465061Z",
     "shell.execute_reply": "2024-12-13T16:39:03.464278Z",
     "shell.execute_reply.started": "2024-12-13T16:34:29.911845Z"
    },
    "id": "OTyy5lf3PUal",
    "outputId": "834762b1-31af-4025-b5e7-74d6093a59d3",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0=======================================\n",
      "------------------Train Result----------------------------\n",
      "Training loss : 0.45532846450805664 | F1_score : 0.4922018620648757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8084    0.9578    0.8768     31801\n",
      "           1     0.7555    0.3650    0.4922     11370\n",
      "\n",
      "    accuracy                         0.8016     43171\n",
      "   macro avg     0.7819    0.6614    0.6845     43171\n",
      "weighted avg     0.7945    0.8016    0.7755     43171\n",
      "\n",
      "------------------Test Result----------------------------\n",
      "Testing loss : 0.3817872405052185 | F1_score : 0.6669282071400549\n",
      "---------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8639    0.9319    0.8967      3952\n",
      "           1     0.7596    0.5944    0.6669      1430\n",
      "\n",
      "    accuracy                         0.8423      5382\n",
      "   macro avg     0.8118    0.7632    0.7818      5382\n",
      "weighted avg     0.8362    0.8423    0.8356      5382\n",
      "\n",
      "Update new best model to : /content/best_GRUmodel.pth\n",
      "Epoch 1=======================================\n",
      "------------------Train Result----------------------------\n",
      "Training loss : 0.3503006398677826 | F1_score : 0.684590490415733\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8695    0.9421    0.9044     31801\n",
      "           1     0.7889    0.6047    0.6846     11370\n",
      "\n",
      "    accuracy                         0.8533     43171\n",
      "   macro avg     0.8292    0.7734    0.7945     43171\n",
      "weighted avg     0.8483    0.8533    0.8465     43171\n",
      "\n",
      "------------------Test Result----------------------------\n",
      "Testing loss : 0.368364155292511 | F1_score : 0.6829463570856685\n",
      "---------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8662    0.9456    0.9042      3952\n",
      "           1     0.7987    0.5965    0.6829      1430\n",
      "\n",
      "    accuracy                         0.8528      5382\n",
      "   macro avg     0.8325    0.7711    0.7936      5382\n",
      "weighted avg     0.8483    0.8528    0.8454      5382\n",
      "\n",
      "Update new best model to : /content/best_GRUmodel.pth\n",
      "Epoch 2=======================================\n",
      "------------------Train Result----------------------------\n",
      "Training loss : 0.30131620168685913 | F1_score : 0.7417692527912968\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8929    0.9429    0.9172     31801\n",
      "           1     0.8107    0.6836    0.7418     11370\n",
      "\n",
      "    accuracy                         0.8746     43171\n",
      "   macro avg     0.8518    0.8133    0.8295     43171\n",
      "weighted avg     0.8712    0.8746    0.8710     43171\n",
      "\n",
      "------------------Test Result----------------------------\n",
      "Testing loss : 0.34692099690437317 | F1_score : 0.7104660045836515\n",
      "---------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8808    0.9347    0.9069      3952\n",
      "           1     0.7828    0.6503    0.7105      1430\n",
      "\n",
      "    accuracy                         0.8592      5382\n",
      "   macro avg     0.8318    0.7925    0.8087      5382\n",
      "weighted avg     0.8548    0.8592    0.8547      5382\n",
      "\n",
      "Update new best model to : /content/best_GRUmodel.pth\n",
      "Epoch 3=======================================\n",
      "------------------Train Result----------------------------\n",
      "Training loss : 0.2573848366737366 | F1_score : 0.7905364816782957\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9144    0.9460    0.9299     31801\n",
      "           1     0.8328    0.7523    0.7905     11370\n",
      "\n",
      "    accuracy                         0.8950     43171\n",
      "   macro avg     0.8736    0.8492    0.8602     43171\n",
      "weighted avg     0.8929    0.8950    0.8932     43171\n",
      "\n",
      "------------------Test Result----------------------------\n",
      "Testing loss : 0.34449970722198486 | F1_score : 0.6994797919167667\n",
      "---------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8711    0.9507    0.9091      3952\n",
      "           1     0.8176    0.6112    0.6995      1430\n",
      "\n",
      "    accuracy                         0.8605      5382\n",
      "   macro avg     0.8443    0.7809    0.8043      5382\n",
      "weighted avg     0.8569    0.8605    0.8534      5382\n",
      "\n",
      "Epoch 4=======================================\n",
      "------------------Train Result----------------------------\n",
      "Training loss : 0.21317395567893982 | F1_score : 0.8377210930750694\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9337    0.9556    0.9445     31801\n",
      "           1     0.8672    0.8102    0.8377     11370\n",
      "\n",
      "    accuracy                         0.9173     43171\n",
      "   macro avg     0.9004    0.8829    0.8911     43171\n",
      "weighted avg     0.9162    0.9173    0.9164     43171\n",
      "\n",
      "------------------Test Result----------------------------\n",
      "Testing loss : 0.37564602494239807 | F1_score : 0.7151304347826087\n",
      "---------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8979    0.8945    0.8962      3952\n",
      "           1     0.7114    0.7189    0.7151      1430\n",
      "\n",
      "    accuracy                         0.8478      5382\n",
      "   macro avg     0.8047    0.8067    0.8057      5382\n",
      "weighted avg     0.8483    0.8478    0.8481      5382\n",
      "\n",
      "Update new best model to : /content/best_GRUmodel.pth\n",
      "Epoch 5=======================================\n",
      "------------------Train Result----------------------------\n",
      "Training loss : 0.16513261198997498 | F1_score : 0.877806601663834\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9516    0.9631    0.9573     31801\n",
      "           1     0.8931    0.8631    0.8778     11370\n",
      "\n",
      "    accuracy                         0.9367     43171\n",
      "   macro avg     0.9223    0.9131    0.9176     43171\n",
      "weighted avg     0.9362    0.9367    0.9364     43171\n",
      "\n",
      "------------------Test Result----------------------------\n",
      "Testing loss : 0.4207930862903595 | F1_score : 0.7018224117875146\n",
      "---------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8760    0.9383    0.9060      3952\n",
      "           1     0.7876    0.6329    0.7018      1430\n",
      "\n",
      "    accuracy                         0.8571      5382\n",
      "   macro avg     0.8318    0.7856    0.8039      5382\n",
      "weighted avg     0.8525    0.8571    0.8518      5382\n",
      "\n",
      "Epoch 6=======================================\n",
      "------------------Train Result----------------------------\n",
      "Training loss : 0.12299606949090958 | F1_score : 0.9146833311173159\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9671    0.9725    0.9698     31801\n",
      "           1     0.9219    0.9076    0.9147     11370\n",
      "\n",
      "    accuracy                         0.9554     43171\n",
      "   macro avg     0.9445    0.9400    0.9423     43171\n",
      "weighted avg     0.9552    0.9554    0.9553     43171\n",
      "\n",
      "------------------Test Result----------------------------\n",
      "Testing loss : 0.47103145718574524 | F1_score : 0.7148536320925191\n",
      "---------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8910    0.9119    0.9013      3952\n",
      "           1     0.7397    0.6916    0.7149      1430\n",
      "\n",
      "    accuracy                         0.8534      5382\n",
      "   macro avg     0.8153    0.8018    0.8081      5382\n",
      "weighted avg     0.8508    0.8534    0.8518      5382\n",
      "\n",
      "Epoch 7=======================================\n",
      "------------------Train Result----------------------------\n",
      "Training loss : 0.09198715537786484 | F1_score : 0.9388422448077772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9766    0.9800    0.9783     31801\n",
      "           1     0.9434    0.9343    0.9388     11370\n",
      "\n",
      "    accuracy                         0.9679     43171\n",
      "   macro avg     0.9600    0.9571    0.9586     43171\n",
      "weighted avg     0.9679    0.9679    0.9679     43171\n",
      "\n",
      "------------------Test Result----------------------------\n",
      "Testing loss : 0.4784201681613922 | F1_score : 0.7099152230003687\n",
      "---------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8861    0.9190    0.9022      3952\n",
      "           1     0.7506    0.6734    0.7099      1430\n",
      "\n",
      "    accuracy                         0.8538      5382\n",
      "   macro avg     0.8183    0.7962    0.8061      5382\n",
      "weighted avg     0.8501    0.8538    0.8511      5382\n",
      "\n",
      "Epoch 8=======================================\n",
      "------------------Train Result----------------------------\n",
      "Training loss : 0.06715718656778336 | F1_score : 0.9567438992159283\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9840    0.9852    0.9846     31801\n",
      "           1     0.9583    0.9551    0.9567     11370\n",
      "\n",
      "    accuracy                         0.9773     43171\n",
      "   macro avg     0.9712    0.9702    0.9707     43171\n",
      "weighted avg     0.9772    0.9773    0.9772     43171\n",
      "\n",
      "------------------Test Result----------------------------\n",
      "Testing loss : 0.5705175399780273 | F1_score : 0.7068513665293897\n",
      "---------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8826    0.9248    0.9032      3952\n",
      "           1     0.7607    0.6601    0.7069      1430\n",
      "\n",
      "    accuracy                         0.8545      5382\n",
      "   macro avg     0.8217    0.7925    0.8051      5382\n",
      "weighted avg     0.8502    0.8545    0.8511      5382\n",
      "\n",
      "Epoch 9=======================================\n",
      "------------------Train Result----------------------------\n",
      "Training loss : 0.05251249670982361 | F1_score : 0.966088258610059\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9874    0.9884    0.9879     31801\n",
      "           1     0.9675    0.9646    0.9661     11370\n",
      "\n",
      "    accuracy                         0.9822     43171\n",
      "   macro avg     0.9775    0.9765    0.9770     43171\n",
      "weighted avg     0.9821    0.9822    0.9822     43171\n",
      "\n",
      "------------------Test Result----------------------------\n",
      "Testing loss : 0.5913235545158386 | F1_score : 0.7070707070707071\n",
      "---------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8828    0.9246    0.9032      3952\n",
      "           1     0.7603    0.6608    0.7071      1430\n",
      "\n",
      "    accuracy                         0.8545      5382\n",
      "   macro avg     0.8215    0.7927    0.8051      5382\n",
      "weighted avg     0.8503    0.8545    0.8511      5382\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(0,epochs):\n",
    "    print(f'Epoch {epoch}=======================================')\n",
    "    train_step(model,train_dataloader,BCE_loss,Adam_optimizer,device = device)\n",
    "    test_step( model,test_dataloader,BCE_loss,Adam_optimizer,device = device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T16:47:43.978296Z",
     "iopub.status.busy": "2024-12-13T16:47:43.977917Z",
     "iopub.status.idle": "2024-12-13T16:47:45.097114Z",
     "shell.execute_reply": "2024-12-13T16:47:45.096281Z",
     "shell.execute_reply.started": "2024-12-13T16:47:43.978251Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------Test Result----------------------------\n",
      "Testing loss : 0.5913235545158386 | F1_score : 0.7070707070707071\n",
      "---------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8828    0.9246    0.9032      3952\n",
      "           1     0.7603    0.6608    0.7071      1430\n",
      "\n",
      "    accuracy                         0.8545      5382\n",
      "   macro avg     0.8215    0.7927    0.8051      5382\n",
      "weighted avg     0.8503    0.8545    0.8511      5382\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_step(model,test_dataloader,BCE_loss,Adam_optimizer,device = device)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6248006,
     "sourceId": 10125021,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6280957,
     "sourceId": 10170154,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
