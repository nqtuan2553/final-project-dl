{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-10T02:10:09.590039Z",
     "iopub.status.busy": "2024-11-10T02:10:09.589752Z",
     "iopub.status.idle": "2024-11-10T02:10:13.112677Z",
     "shell.execute_reply": "2024-11-10T02:10:13.111715Z",
     "shell.execute_reply.started": "2024-11-10T02:10:09.590002Z"
    },
    "id": "mQWCGFilVnS7",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "dev = pd.read_csv('val.csv')\n",
    "train = train.dropna()\n",
    "dev = dev.dropna()\n",
    "\n",
    "train['text'] = train['text'].astype(str)\n",
    "#train['label'] = 1\n",
    "X_train = train['text']\n",
    "y_train = train[\"label\"]\n",
    "\n",
    "dev['text'] = dev['text'].astype(str)\n",
    "X_valid = dev['text']\n",
    "y_valid = dev['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-10T02:10:28.999503Z",
     "iopub.status.busy": "2024-11-10T02:10:28.999030Z",
     "iopub.status.idle": "2024-11-10T02:10:29.044427Z",
     "shell.execute_reply": "2024-11-10T02:10:29.043514Z",
     "shell.execute_reply.started": "2024-11-10T02:10:28.999467Z"
    },
    "id": "5jTYkrtMVnS8",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_sentences = list(train['text'].values)\n",
    "train_labels = list(train['label'].values)\n",
    "\n",
    "dev_sentences = list(dev['text'].values)\n",
    "dev_labels = list(dev['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-10T02:10:30.928426Z",
     "iopub.status.busy": "2024-11-10T02:10:30.928028Z"
    },
    "id": "UVppgTK5VnS9",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "encoded_labels = le.transform(train_labels)\n",
    "encoded_dev_labels = le.transform(dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f7808335cbc437dbf89d323c947f86b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/678 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b6b9a1ef6cc45378bd86beaf083d697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/895k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24017397aa3346cb959052c4ca809f77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "bpe.codes:   0%|          | 0.00/1.14M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "171e05e3757540c7a8f87ada1b5e8565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/3.13M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd79590a46584bd99ed0dd64fa9080a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/540M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at vinai/phobert-base-v2 and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('vinai/phobert-base-v2')\n",
    "phoBert = AutoModel.from_pretrained('vinai/phobert-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ULP2-SfGVnS9",
    "outputId": "e1f5b529-2b11-468f-f4f8-3d94f04e3516",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/43171 [00:00<?, ?it/s]/workspace/thviet/LLMs/Monolingual/drop-rag/.conda/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2829: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|██████████| 43171/43171 [00:16<00:00, 2612.67it/s]\n",
      "100%|██████████| 5382/5382 [00:01<00:00, 2837.68it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "def encoder_generator(sentences,labels):\n",
    "\n",
    "\n",
    "    sent_index1 = []\n",
    "    sent_index2 = []\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    decoder_labels = []\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    for index, sent in enumerate(tqdm(sentences)):\n",
    "        sent_index1.append(index)\n",
    "\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "            sent,\n",
    "            add_special_tokens=True,\n",
    "            max_length=128,\n",
    "            pad_to_max_length=True,\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids.append(encoded_dict['input_ids'].to(device))\n",
    "        attention_masks.append(encoded_dict['attention_mask'].to(device))\n",
    "    # Concatenate and move final tensors to the GPU\n",
    "    input_ids = torch.cat(input_ids, dim=0).to(device)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0).to(device)\n",
    "    #decoder_labels = torch.cat(decoder_labels,dim=0).to(device)\n",
    "    labels = torch.tensor(labels).to(device)\n",
    "    sent_index1 = torch.tensor(sent_index1).to(device)\n",
    "    \n",
    "    return sent_index1, input_ids, attention_masks, labels\n",
    "\n",
    "train_sent_index,train_input_ids,train_attention_masks,train_encoded_label_tensors = encoder_generator(train_sentences,train_labels)\n",
    "dev_sent_index,dev_input_ids,dev_attention_masks,dev_encoded_label_tensors = encoder_generator(dev_sentences,dev_labels)\n",
    "#print('Original: ', train_sentences[0])\n",
    "#print('Token IDs:', train_input_ids[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs: tensor([    0,   266,  6344, 18150,  1204,    88,   238,   118,    17,  7708,\n",
      "            3,  3965,   344,   988,    77,    59,  6205,  6266,     6,  7130,\n",
      "        45572,  1301,     4,    59,  1061, 41086,     6,    17,    10,    61,\n",
      "        14457,  9970,    12, 27772,     4,    15,   139,    47,   939,   520,\n",
      "        10793,  5796,  1384,     4,   122,    13,    18,   305,  4263,   154,\n",
      "           11,    61,    72,  2270,  1494, 39951,  1494, 39951,    59,  1088,\n",
      "        42245, 13208,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "            2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "            2,     2,     2,     2,     2,     2,     2,     2],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print('Token IDs:', train_input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iAxKUO19VnS-",
    "outputId": "397c3707-3a0c-4c7b-8f9a-44d2482d9e19",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print('Original: ', train_sentences[:10])\n",
    "print('Token IDs:', train_input_ids[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3qzKvD36VnS-",
    "outputId": "567ed3c7-255c-4919-ba5c-7fa5d2ff4a73",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data samples is 43171\n",
      "valid data samples is 5382\n"
     ]
    }
   ],
   "source": [
    "# Connvert train, dev input by using TensorDataset\n",
    "\n",
    "from torch.utils.data import TensorDataset,random_split\n",
    "\n",
    "train_dataset = TensorDataset(train_input_ids,train_encoded_label_tensors,train_attention_masks)\n",
    "#train_attention_masks,\n",
    "dev_dataset = TensorDataset(dev_input_ids,dev_encoded_label_tensors,dev_attention_masks)\n",
    "#,dev_attention_masks\n",
    "\n",
    "print('train data samples is {}'.format(len(train_dataset)))\n",
    "print(\"valid data samples is {}\".format(len(dev_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "muSvExPiVnS-",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,RandomSampler,SequentialSampler\n",
    "\n",
    "bs=32\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset,\n",
    "                              sampler=RandomSampler(train_dataset),\n",
    "                              batch_size=bs)\n",
    "valid_data_loader = DataLoader(dev_dataset,\n",
    "                              sampler=RandomSampler(dev_dataset),\n",
    "                              batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/workspace/thviet/LLMs/Monolingual/val_data_loader.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(train_data_loader, '/workspace/thviet/LLMs/Monolingual/train_data_loader.pkl')\n",
    "joblib.dump(valid_data_loader, '/workspace/thviet/LLMs/Monolingual/val_data_loader.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/workspace/thviet/LLMs/Monolingual/toxic/test_data_loader.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(test_data_loader, '/workspace/thviet/LLMs/Monolingual/toxic/test_data_loader.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3v0rBLYUVnS-",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BCNN(nn.Module):\n",
    "    def __init__(self, embedding_dim, output_dim,\n",
    "                 dropout,bidirectional_units,conv_filters):\n",
    "\n",
    "        super().__init__()\n",
    "        self.bert = phoBert\n",
    "        #.fc_input = nn.Linear(embedding_dim,embedding_dim)\n",
    "        self.bidirectional_lstm = nn.LSTM(\n",
    "            embedding_dim, bidirectional_units, bidirectional=True, batch_first=True\n",
    "        )\n",
    "        self.conv1 = nn.Conv1d(in_channels=2*bidirectional_units, out_channels=conv_filters[0], kernel_size=4)\n",
    "        self.conv2 = nn.Conv1d(in_channels=2*bidirectional_units, out_channels=conv_filters[1], kernel_size=5)\n",
    "\n",
    "        self.fc = nn.Linear(64, output_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,b_input_ids,b_input_mask):\n",
    "        encoded = self.bert(b_input_ids,b_input_mask)[0]\n",
    "        embedded, _ = self.bidirectional_lstm(encoded)\n",
    "        embedded = embedded.permute(0, 2, 1)\n",
    "        conved_1 = F.relu(self.conv1(embedded))\n",
    "        conved_2 = F.relu(self.conv2(embedded))\n",
    "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
    "\n",
    "        pooled_1 = F.max_pool1d(conved_1, conved_1.shape[2]).squeeze(2)\n",
    "        pooled_2 = F.max_pool1d(conved_2, conved_2.shape[2]).squeeze(2)\n",
    "        #pooled_n = [batch size, n_fibatlters]\n",
    "\n",
    "        cat = self.dropout(torch.cat((pooled_1, pooled_2), dim = 1))\n",
    "\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "\n",
    "        result =  self.fc(cat)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "GpgY3BSbVnS-",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "EMBEDDING_DIM = 768\n",
    "OUTPUT_DIM = 2\n",
    "DROPOUT = 0.1\n",
    "CONV_FILTERS = [32, 32]  # Number of filters for each kernel size (4 and 5)\n",
    "BIDIRECTIONAL_UNITS = 128\n",
    "cnn = BCNN(EMBEDDING_DIM, OUTPUT_DIM, DROPOUT, BIDIRECTIONAL_UNITS, CONV_FILTERS)\n",
    "#cnn = cnn.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ukdj7VGVnS_"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ahT93jsSVnTA"
   },
   "source": [
    "Thiết lập optimizer Adam cho mô hình, kết hợp các tham số từ cả PhoBERT và CNN.\n",
    " Khởi tạo hàm mất mát Cross Entropy, thường được sử dụng cho các bài toán phân loại đa lớp.\n",
    "Hàm mất mát cũng được chuyển sang thiết bị tính toán để sẵn sàng cho quá trình huấn luyện."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Kd_1Yf_1VnTA",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model_prameters = list(cnn.parameters())\n",
    "\n",
    "optimizer = optim.Adam(model_prameters,lr=2e-5,eps=1e-8)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "5hdKazx7VnTA",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def categorical_accuracy(preds, y):\n",
    "    max_preds = preds.argmax(dim=1, keepdim=True)  # Lấy chỉ số của xác suất cao nhất\n",
    "    correct = max_preds.squeeze(1).eq(y.to(preds.device))  # Đảm bảo y nằm cùng thiết bị với preds\n",
    "    return correct.sum() / torch.FloatTensor([y.shape[0]]).to(preds.device)  # Đảm bảo tất cả tensor nằm cùng thiết bị"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "DUJkFHWRVnTB",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Def for training\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train():\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    phoBert.train()\n",
    "    cnn.train()\n",
    "    for batch in tqdm(train_data_loader):\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_labels = batch[1].to(device)\n",
    "        b_input_mask = batch[2].to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = cnn(b_input_ids,b_input_mask)\n",
    "        #, decoder_input_ids=b_labels\n",
    "        #hidden_states = outputs.hidden_states\n",
    "        #embedded = hidden_states[-1]\n",
    "        '''predictions = cnn(outputs)'''\n",
    "\n",
    "        loss = criterion(predictions, b_labels)\n",
    "        #.long()\n",
    "\n",
    "        acc = categorical_accuracy(predictions, b_labels)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(train_data_loader), epoch_acc / len(train_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2vViT3rJVnTB",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Class for predict label\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def predictions_labels(preds,labels):\n",
    "    pred = np.argmax(preds,axis=1).flatten()\n",
    "    label = labels.flatten()\n",
    "    return pred,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "m9SpO-_tVnTB",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,accuracy_score,f1_score\n",
    "def eval():\n",
    "    epoch_loss = 0\n",
    "\n",
    "    total_predictions = []\n",
    "    total_true = []\n",
    "\n",
    "    all_true_labels = []\n",
    "    all_pred_labels = []\n",
    "    cnn.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch in tqdm(valid_data_loader):\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_labels = batch[1].to(device)\n",
    "            b_input_mask = batch[2].to(device)\n",
    "           \n",
    "\n",
    "            predictions = cnn(b_input_ids,b_input_mask)\n",
    "            #hidden_states = outputs.hidden_states\n",
    "            #embedded = outputs.encoder_last_hidden_state\n",
    "            ''' predictions = cnn(outputs)'''\n",
    "\n",
    "            loss = criterion(predictions, b_labels)\n",
    "            #.long()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            predictions = predictions.detach().cpu().numpy()\n",
    "\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "            pred,true = predictions_labels(predictions,label_ids)\n",
    "\n",
    "            all_pred_labels.extend(pred)\n",
    "            all_true_labels.extend(true)\n",
    "\n",
    "    print(classification_report(all_pred_labels,all_true_labels))\n",
    "    avg_val_accuracy = accuracy_score(all_pred_labels,all_true_labels)\n",
    "    macro_f1_score = f1_score(all_pred_labels,all_true_labels,average='macro')\n",
    "\n",
    "    avg_val_loss = epoch_loss/len(valid_data_loader)\n",
    "\n",
    "    print(\"accuracy = {0:.2f}\".format(avg_val_accuracy))\n",
    "    return avg_val_loss,avg_val_accuracy,macro_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "2JdVeYqXVnTB",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Time for training\n",
    "\n",
    "import time\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v4aZHuEoVnTB",
    "outputId": "65ec2950-7a0a-48aa-cc72-1d369a805978",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1350/1350 [04:33<00:00,  4.93it/s]\n",
      "100%|██████████| 169/169 [00:11<00:00, 14.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91      4376\n",
      "           1       0.60      0.86      0.71      1006\n",
      "\n",
      "    accuracy                           0.87      5382\n",
      "   macro avg       0.78      0.86      0.81      5382\n",
      "weighted avg       0.90      0.87      0.87      5382\n",
      "\n",
      "accuracy = 0.87\n",
      "model saved\n",
      "Epoch: 01 | Epoch Time: 4m 45s\n",
      "\tTrain Loss: 0.383 | Train acc: 83.90%\n",
      "\t Val. Loss: 0.342 |  Val. acc: 86.58%\n",
      "\t Val. Loss: 0.342 |  Val. F1: 80.92%\n",
      "=============Epoch Ended==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1350/1350 [04:43<00:00,  4.76it/s]\n",
      "100%|██████████| 169/169 [00:12<00:00, 13.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92      4106\n",
      "           1       0.71      0.81      0.76      1276\n",
      "\n",
      "    accuracy                           0.88      5382\n",
      "   macro avg       0.83      0.85      0.84      5382\n",
      "weighted avg       0.89      0.88      0.88      5382\n",
      "\n",
      "accuracy = 0.88\n",
      "model saved\n",
      "Epoch: 02 | Epoch Time: 4m 56s\n",
      "\tTrain Loss: 0.288 | Train acc: 88.23%\n",
      "\t Val. Loss: 0.310 |  Val. acc: 87.81%\n",
      "\t Val. Loss: 0.310 |  Val. F1: 83.86%\n",
      "=============Epoch Ended==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1350/1350 [04:42<00:00,  4.78it/s]\n",
      "100%|██████████| 169/169 [00:12<00:00, 14.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90      3776\n",
      "           1       0.79      0.71      0.75      1606\n",
      "\n",
      "    accuracy                           0.86      5382\n",
      "   macro avg       0.83      0.81      0.82      5382\n",
      "weighted avg       0.85      0.86      0.85      5382\n",
      "\n",
      "accuracy = 0.86\n",
      "Epoch: 03 | Epoch Time: 4m 54s\n",
      "\tTrain Loss: 0.230 | Train acc: 90.98%\n",
      "\t Val. Loss: 0.351 |  Val. acc: 85.62%\n",
      "\t Val. Loss: 0.351 |  Val. F1: 82.29%\n",
      "=============Epoch Ended==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1350/1350 [04:44<00:00,  4.74it/s]\n",
      "100%|██████████| 169/169 [00:12<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91      3960\n",
      "           1       0.74      0.75      0.75      1422\n",
      "\n",
      "    accuracy                           0.86      5382\n",
      "   macro avg       0.83      0.83      0.83      5382\n",
      "weighted avg       0.87      0.86      0.87      5382\n",
      "\n",
      "accuracy = 0.86\n",
      "Epoch: 04 | Epoch Time: 4m 57s\n",
      "\tTrain Loss: 0.183 | Train acc: 92.82%\n",
      "\t Val. Loss: 0.347 |  Val. acc: 86.47%\n",
      "\t Val. Loss: 0.347 |  Val. F1: 82.69%\n",
      "=============Epoch Ended==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1350/1350 [04:43<00:00,  4.76it/s]\n",
      "100%|██████████| 169/169 [00:11<00:00, 14.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91      4005\n",
      "           1       0.73      0.77      0.75      1377\n",
      "\n",
      "    accuracy                           0.87      5382\n",
      "   macro avg       0.83      0.84      0.83      5382\n",
      "weighted avg       0.87      0.87      0.87      5382\n",
      "\n",
      "accuracy = 0.87\n",
      "Epoch: 05 | Epoch Time: 4m 55s\n",
      "\tTrain Loss: 0.138 | Train acc: 94.87%\n",
      "\t Val. Loss: 0.380 |  Val. acc: 87.01%\n",
      "\t Val. Loss: 0.380 |  Val. F1: 83.21%\n",
      "=============Epoch Ended==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1350/1350 [04:43<00:00,  4.76it/s]\n",
      "100%|██████████| 169/169 [00:12<00:00, 13.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91      4005\n",
      "           1       0.72      0.76      0.74      1377\n",
      "\n",
      "    accuracy                           0.86      5382\n",
      "   macro avg       0.82      0.83      0.82      5382\n",
      "weighted avg       0.86      0.86      0.86      5382\n",
      "\n",
      "accuracy = 0.86\n",
      "Epoch: 06 | Epoch Time: 4m 56s\n",
      "\tTrain Loss: 0.105 | Train acc: 96.15%\n",
      "\t Val. Loss: 0.485 |  Val. acc: 86.23%\n",
      "\t Val. Loss: 0.485 |  Val. F1: 82.20%\n",
      "=============Epoch Ended==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1350/1350 [04:46<00:00,  4.71it/s]\n",
      "100%|██████████| 169/169 [00:12<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91      4092\n",
      "           1       0.68      0.76      0.72      1290\n",
      "\n",
      "    accuracy                           0.86      5382\n",
      "   macro avg       0.80      0.83      0.81      5382\n",
      "weighted avg       0.87      0.86      0.86      5382\n",
      "\n",
      "accuracy = 0.86\n",
      "Epoch: 07 | Epoch Time: 4m 59s\n",
      "\tTrain Loss: 0.085 | Train acc: 96.93%\n",
      "\t Val. Loss: 0.560 |  Val. acc: 85.84%\n",
      "\t Val. Loss: 0.560 |  Val. F1: 81.32%\n",
      "=============Epoch Ended==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1350/1350 [04:43<00:00,  4.77it/s]\n",
      "100%|██████████| 169/169 [00:12<00:00, 14.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.90      4047\n",
      "           1       0.69      0.75      0.72      1335\n",
      "\n",
      "    accuracy                           0.86      5382\n",
      "   macro avg       0.80      0.82      0.81      5382\n",
      "weighted avg       0.86      0.86      0.86      5382\n",
      "\n",
      "accuracy = 0.86\n",
      "Epoch: 08 | Epoch Time: 4m 55s\n",
      "\tTrain Loss: 0.064 | Train acc: 97.74%\n",
      "\t Val. Loss: 0.573 |  Val. acc: 85.60%\n",
      "\t Val. Loss: 0.573 |  Val. F1: 81.20%\n",
      "=============Epoch Ended==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1350/1350 [04:44<00:00,  4.75it/s]\n",
      "100%|██████████| 169/169 [00:12<00:00, 14.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91      4081\n",
      "           1       0.70      0.77      0.73      1301\n",
      "\n",
      "    accuracy                           0.86      5382\n",
      "   macro avg       0.81      0.83      0.82      5382\n",
      "weighted avg       0.87      0.86      0.87      5382\n",
      "\n",
      "accuracy = 0.86\n",
      "Epoch: 09 | Epoch Time: 4m 56s\n",
      "\tTrain Loss: 0.057 | Train acc: 98.00%\n",
      "\t Val. Loss: 0.650 |  Val. acc: 86.31%\n",
      "\t Val. Loss: 0.650 |  Val. F1: 81.98%\n",
      "=============Epoch Ended==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1350/1350 [04:44<00:00,  4.75it/s]\n",
      "100%|██████████| 169/169 [00:11<00:00, 14.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91      4098\n",
      "           1       0.69      0.78      0.73      1284\n",
      "\n",
      "    accuracy                           0.86      5382\n",
      "   macro avg       0.81      0.83      0.82      5382\n",
      "weighted avg       0.87      0.86      0.87      5382\n",
      "\n",
      "accuracy = 0.86\n",
      "Epoch: 10 | Epoch Time: 4m 55s\n",
      "\tTrain Loss: 0.045 | Train acc: 98.45%\n",
      "\t Val. Loss: 0.706 |  Val. acc: 86.36%\n",
      "\t Val. Loss: 0.706 |  Val. F1: 81.98%\n",
      "=============Epoch Ended==============\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "best_macro_f1 = float('0')\n",
    "#phoBert.to(device)\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_loss,train_acc = train()\n",
    "    valid_loss,valid_acc,macro_f1 = eval()\n",
    "    end_time = time.time()\n",
    "\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if macro_f1 > best_macro_f1:\n",
    "        best_macro_f1 = macro_f1\n",
    "        #torch.save(phoBert,'phobert.pt')\n",
    "        torch.save(cnn,'toxic.pt')\n",
    "        print(\"model saved\")\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. acc: {valid_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. F1: {macro_f1*100:.2f}%')\n",
    "    print('=============Epoch Ended==============')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "64U4NqK0VnTC",
    "outputId": "4e8081d5-085c-4dc8-d934-3194998c0c88",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_244037/1756912611.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  cnn = torch.load(r'toxic.pt')\n"
     ]
    }
   ],
   "source": [
    "cnn = torch.load(r'toxic.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BCNN(\n",
       "  (bert): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(258, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (bidirectional_lstm): LSTM(768, 128, batch_first=True, bidirectional=True)\n",
       "  (conv1): Conv1d(256, 32, kernel_size=(4,), stride=(1,))\n",
       "  (conv2): Conv1d(256, 32, kernel_size=(5,), stride=(1,))\n",
       "  (fc): Linear(in_features=64, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test = pd.read_csv('test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.dropna()\n",
    "X_test = test['text']\n",
    "y_test = test['label']\n",
    "test_sentences = list(test['text'].values)\n",
    "test_labels = list(test['label'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def encoder_generator(sentences,labels):\n",
    "\n",
    "\n",
    "    sent_index1 = []\n",
    "    sent_index2 = []\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    decoder_labels = []\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    for index, sent in enumerate(tqdm(sentences)):\n",
    "        sent_index1.append(index)\n",
    "\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "            sent,\n",
    "            add_special_tokens=True,\n",
    "            max_length=128,\n",
    "            pad_to_max_length=True,\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids.append(encoded_dict['input_ids'].to(device))\n",
    "        attention_masks.append(encoded_dict['attention_mask'].to(device))\n",
    "    # Concatenate and move final tensors to the GPU\n",
    "    input_ids = torch.cat(input_ids, dim=0).to(device)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0).to(device)\n",
    "    #decoder_labels = torch.cat(decoder_labels,dim=0).to(device)\n",
    "    labels = torch.tensor(labels).to(device)\n",
    "    sent_index1 = torch.tensor(sent_index1).to(device)\n",
    "    \n",
    "    return sent_index1, input_ids, attention_masks, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rqEjMgadVnTC",
    "outputId": "2a4bf732-7d94-4844-ab36-f91c1e4db2a6",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5382/5382 [00:01<00:00, 3375.42it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset,random_split,DataLoader,RandomSampler\n",
    "test_sent_index, test_input_ids, test_attention_masks, test_encoded_label_tensors = encoder_generator(test_sentences,test_labels)\n",
    "test_dataset = TensorDataset(test_input_ids,test_encoded_label_tensors,test_attention_masks)\n",
    "test_data_loader = DataLoader(test_dataset,\n",
    "                              sampler=RandomSampler(test_dataset),\n",
    "                              batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169/169 [00:11<00:00, 15.30it/s]\n"
     ]
    }
   ],
   "source": [
    "all_pred_labels = []\n",
    "all_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "  for batch in tqdm(test_data_loader):\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[2].to(device)\n",
    "    b_labels = batch[1].to(device)\n",
    "    predictions = cnn(b_input_ids,b_input_mask)\n",
    "    \n",
    "\n",
    "\n",
    "    predictions = predictions.detach().cpu().numpy()\n",
    "\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    pred, true = predictions_labels(predictions, label_ids)\n",
    "\n",
    "    all_pred_labels.extend(pred)\n",
    "    all_true_labels.extend(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "_ja1ix-rVnTC",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9405    0.8978    0.9187      4140\n",
      "           1     0.7042    0.8108    0.7537      1242\n",
      "\n",
      "    accuracy                         0.8777      5382\n",
      "   macro avg     0.8224    0.8543    0.8362      5382\n",
      "weighted avg     0.8860    0.8777    0.8806      5382\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The final score in the test set (classification report)\n",
    "\n",
    "print(classification_report(all_pred_labels,all_true_labels, digits = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "lKT1OhdTVnTC",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 - micro: 0.8777406168710516\n",
      "F1 - macro: 0.8362138180386631\n"
     ]
    }
   ],
   "source": [
    "evaluation = f1_score(all_true_labels, all_pred_labels, average='micro')\n",
    "\n",
    "print(\"F1 - micro: \" + str(evaluation))\n",
    "\n",
    "evaluation = f1_score(all_true_labels, all_pred_labels, average='macro')\n",
    "print(\"F1 - macro: \" + str(evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "F3A4xEOKVnTC",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "# Import the confusion_matrix function from sklearn.metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cf1 = confusion_matrix(all_true_labels, all_pred_labels)\n",
    "df_cm1 = pd.DataFrame(cf1, index = [\"non-toxic\",\"toxic\"],\n",
    "                  columns = [\"non-toxic\",\"toxic\"])\n",
    "plt.clf()\n",
    "sn.heatmap(df_cm1, annot=True, cmap=\"Greys\",fmt='g', cbar=True, annot_kws={\"size\": 30})"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5316719,
     "sourceId": 8835212,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
